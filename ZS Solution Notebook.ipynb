{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Datasets/zs2\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr_tweet_1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tr_tweet_2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tr_tweet_3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0  Tr_tweet_1           neutral                        1.0000            NaN   \n",
       "1  Tr_tweet_2          positive                        0.3486            NaN   \n",
       "2  Tr_tweet_3           neutral                        0.6837            NaN   \n",
       "3  Tr_tweet_4          negative                        1.0000     Bad Flight   \n",
       "4  Tr_tweet_5          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline        name  retweet_count  \\\n",
       "0                        NaN  Virgin America     cairdin            0.0   \n",
       "1                     0.0000  Virgin America    jnardino            0.0   \n",
       "2                        NaN  Virgin America  yvonnalynn            0.0   \n",
       "3                     0.7033  Virgin America    jnardino            0.0   \n",
       "4                     1.0000  Virgin America    jnardino            0.0   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_tweet_1</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>pilot</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_tweet_2</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>idk_but_youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>2015-02-24 10:48:24 -0800</td>\n",
       "      <td>1/1 loner squad</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_tweet_3</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>mollanderson</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>2015-02-24 10:21:28 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_tweet_4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>heatherovieda</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>2015-02-24 09:39:46 -0800</td>\n",
       "      <td>this place called NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_tweet_5</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>KGervaise</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I have an unused ticket but mov...</td>\n",
       "      <td>2015-02-23 16:20:38 -0800</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  airline_sentiment_confidence negativereason  \\\n",
       "0  Test_tweet_1                        0.6340            NaN   \n",
       "1  Test_tweet_2                        0.6769            NaN   \n",
       "2  Test_tweet_3                        0.6451            NaN   \n",
       "3  Test_tweet_4                        1.0000     Bad Flight   \n",
       "4  Test_tweet_5                        0.6578            NaN   \n",
       "\n",
       "   negativereason_confidence         airline             name  retweet_count  \\\n",
       "0                        NaN  Virgin America            pilot              0   \n",
       "1                        0.0  Virgin America  idk_but_youtube              0   \n",
       "2                        NaN  Virgin America     mollanderson              0   \n",
       "3                        1.0  Virgin America    heatherovieda              0   \n",
       "4                        0.0  Virgin America        KGervaise              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  @VirginAmerica Really missed a prime opportuni...   \n",
       "1  @VirginAmerica did you know that suicide is th...   \n",
       "2  @VirginAmerica @virginmedia I'm flying your #f...   \n",
       "3  @VirginAmerica  I flew from NYC to SFO last we...   \n",
       "4  @VirginAmerica I have an unused ticket but mov...   \n",
       "\n",
       "               tweet_created         tweet_location  \\\n",
       "0  2015-02-24 11:12:29 -0800            Los Angeles   \n",
       "1  2015-02-24 10:48:24 -0800        1/1 loner squad   \n",
       "2  2015-02-24 10:21:28 -0800                    NaN   \n",
       "3  2015-02-24 09:39:46 -0800  this place called NYC   \n",
       "4  2015-02-23 16:20:38 -0800                Georgia   \n",
       "\n",
       "                user_timezone  \n",
       "0  Pacific Time (US & Canada)  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2  Eastern Time (US & Canada)  \n",
       "3  Eastern Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('test.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         object\n",
       "airline_sentiment                object\n",
       "airline_sentiment_confidence    float64\n",
       "negativereason                   object\n",
       "negativereason_confidence       float64\n",
       "airline                          object\n",
       "name                             object\n",
       "retweet_count                   float64\n",
       "text                             object\n",
       "tweet_created                    object\n",
       "tweet_location                   object\n",
       "user_timezone                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3339, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            2884\n",
       "Virgin America     454\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                           0\n",
       "airline_sentiment                  0\n",
       "airline_sentiment_confidence       0\n",
       "negativereason                  1205\n",
       "negativereason_confidence        889\n",
       "airline                            1\n",
       "name                               1\n",
       "retweet_count                      1\n",
       "text                               1\n",
       "tweet_created                     96\n",
       "tweet_location                  1020\n",
       "user_timezone                   1108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                          0\n",
       "airline_sentiment_confidence      0\n",
       "negativereason                  117\n",
       "negativereason_confidence        82\n",
       "airline                           0\n",
       "name                              0\n",
       "retweet_count                     0\n",
       "text                              0\n",
       "tweet_created                    10\n",
       "tweet_location                  111\n",
       "user_timezone                   123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['name','tweet_location','user_timezone','tweet_created','negativereason'],axis=1,inplace=True)\n",
    "\n",
    "df2.drop(['name','tweet_location','user_timezone','tweet_created','negativereason'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negativereason_confidence']=df['negativereason_confidence'].fillna(df['negativereason_confidence'].mean())\n",
    "df2['negativereason_confidence']=df2['negativereason_confidence'].fillna(df2['negativereason_confidence'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        0\n",
       "airline_sentiment               0\n",
       "airline_sentiment_confidence    0\n",
       "negativereason_confidence       0\n",
       "airline                         0\n",
       "retweet_count                   0\n",
       "text                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        0\n",
       "airline_sentiment_confidence    0\n",
       "negativereason_confidence       0\n",
       "airline                         0\n",
       "retweet_count                   0\n",
       "text                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(df['text']) is str:\n",
    "        df['text'] = df['text'].lower()\n",
    "        \n",
    "        \n",
    "if type(df2['text']) is str:\n",
    "        df2['text'] = df2['text'].lower()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = re.sub(\"[^a-zA-Z0-9\\s]\",  # Search for all non-letters\n",
    "                          \" \",          # Replace all non-letters with spaces\n",
    "                          str(df2['text']))\n",
    "\n",
    "df2['text'] = re.sub(\"[^a-zA-Z0-9\\s]\",  # Search for all non-letters\n",
    "                          \" \",          # Replace all non-letters with spaces\n",
    "                          str(df2['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2134\n",
       "neutral      679\n",
       "positive     525\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.airline_sentiment==\"negative\"]\n",
    "df_minority_1 = df[df.airline_sentiment==\"neutral\"]\n",
    "df_minority_2 = df[df.airline_sentiment==\"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_1_upsampled = resample(df_minority_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2134,    # to match majority class\n",
    "                                 random_state=50) \n",
    "\n",
    "\n",
    "df_minority_2_upsampled = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2134,    # to match majority class\n",
    "                                 random_state=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_majority, df_minority_1_upsampled,df_minority_2_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2134\n",
       "positive    2134\n",
       "negative    2134\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tr_tweet_6</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tr_tweet_13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tr_tweet_17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "3    Tr_tweet_4          negative                        1.0000   \n",
       "4    Tr_tweet_5          negative                        1.0000   \n",
       "5    Tr_tweet_6          negative                        1.0000   \n",
       "12  Tr_tweet_13          negative                        0.6842   \n",
       "16  Tr_tweet_17          negative                        0.6705   \n",
       "\n",
       "    negativereason_confidence         airline  retweet_count  \\\n",
       "3                      0.7033  Virgin America            0.0   \n",
       "4                      1.0000  Virgin America            0.0   \n",
       "5                      0.6842  Virgin America            0.0   \n",
       "12                     0.3684  Virgin America            0.0   \n",
       "16                     0.3614  Virgin America            0.0   \n",
       "\n",
       "                                                 text  \n",
       "3   0       VirginAmerica Really missed a prime op...  \n",
       "4   0       VirginAmerica Really missed a prime op...  \n",
       "5   0       VirginAmerica Really missed a prime op...  \n",
       "12  0       VirginAmerica Really missed a prime op...  \n",
       "16  0       VirginAmerica Really missed a prime op...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No. of words in the text ##\n",
    "df[\"num_words\"] = df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "df2[\"num_words\"] = df2[\"text\"].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of unique words in the text ##\n",
    "df[\"num_unique_words\"] = df[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "df2[\"num_unique_words\"] = df2[\"text\"].apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of characters in the text ##\n",
    "df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(str(x)))\n",
    "df2[\"num_chars\"] = df2[\"text\"].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of stopwords in the text ##\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "df[\"num_stopwords\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "df2[\"num_stopwords\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of punctuations in the text ##\n",
    "import string\n",
    "\n",
    "df[\"num_punctuations\"] =df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "df2[\"num_punctuations\"] =df2['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of title case words in the text ##\n",
    "df[\"num_words_upper\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "df2[\"num_words_upper\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of title case words in the text ##\n",
    "df[\"num_words_title\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "df2[\"num_words_title\"] = df2[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average length of the words in the text ##\n",
    "df[\"mean_word_len\"] = df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "df2[\"mean_word_len\"] = df2[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>512</td>\n",
       "      <td>311</td>\n",
       "      <td>3515</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>4.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>512</td>\n",
       "      <td>311</td>\n",
       "      <td>3515</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>4.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tr_tweet_6</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>512</td>\n",
       "      <td>311</td>\n",
       "      <td>3515</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>4.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tr_tweet_13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>512</td>\n",
       "      <td>311</td>\n",
       "      <td>3515</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>4.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tr_tweet_17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>512</td>\n",
       "      <td>311</td>\n",
       "      <td>3515</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>4.410156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "3    Tr_tweet_4          negative                        1.0000   \n",
       "4    Tr_tweet_5          negative                        1.0000   \n",
       "5    Tr_tweet_6          negative                        1.0000   \n",
       "12  Tr_tweet_13          negative                        0.6842   \n",
       "16  Tr_tweet_17          negative                        0.6705   \n",
       "\n",
       "    negativereason_confidence         airline  retweet_count  \\\n",
       "3                      0.7033  Virgin America            0.0   \n",
       "4                      1.0000  Virgin America            0.0   \n",
       "5                      0.6842  Virgin America            0.0   \n",
       "12                     0.3684  Virgin America            0.0   \n",
       "16                     0.3614  Virgin America            0.0   \n",
       "\n",
       "                                                 text  num_words  \\\n",
       "3   0       VirginAmerica Really missed a prime op...        512   \n",
       "4   0       VirginAmerica Really missed a prime op...        512   \n",
       "5   0       VirginAmerica Really missed a prime op...        512   \n",
       "12  0       VirginAmerica Really missed a prime op...        512   \n",
       "16  0       VirginAmerica Really missed a prime op...        512   \n",
       "\n",
       "    num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
       "3                311       3515            178                 0   \n",
       "4                311       3515            178                 0   \n",
       "5                311       3515            178                 0   \n",
       "12               311       3515            178                 0   \n",
       "16               311       3515            178                 0   \n",
       "\n",
       "    num_words_upper  num_words_title  mean_word_len  \n",
       "3                27               46       4.410156  \n",
       "4                27               46       4.410156  \n",
       "5                27               46       4.410156  \n",
       "12               27               46       4.410156  \n",
       "16               27               46       4.410156  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id   3298\n",
      "airline_sentiment   3\n",
      "airline_sentiment_confidence   516\n",
      "negativereason_confidence   730\n",
      "airline   2\n",
      "retweet_count   5\n",
      "text   1\n",
      "num_words   1\n",
      "num_unique_words   1\n",
      "num_chars   1\n",
      "num_stopwords   1\n",
      "num_punctuations   1\n",
      "num_words_upper   1\n",
      "num_words_title   1\n",
      "mean_word_len   1\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,' ',df[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['num_words','num_unique_words','num_chars','num_stopwords','num_punctuations','num_words_upper','num_words_title','mean_word_len'],axis=1,inplace=True)\n",
    "\n",
    "df2.drop(['num_words','num_unique_words','num_chars','num_stopwords','num_punctuations','num_words_upper','num_words_title','mean_word_len'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['airline_sentiment']\n",
    "\n",
    "df.drop('airline_sentiment',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras.preprocessing.sequence import pad_sequences\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\\nfrom sklearn.model_selection import train_test_split\\nfrom keras.utils.np_utils import to_categorical\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAX_NB_WORDS = 20000\\nmaxlen = 120  # cut texts after this number of words (among top max_features most common words)\\nbatch_size = 32\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MAX_NB_WORDS = 20000\n",
    "maxlen = 120  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\\ntokenizer.fit_on_texts(texts_train)\\nsequences = tokenizer.texts_to_sequences(texts_train)\\nsequences_test = tokenizer.texts_to_sequences(texts_test)\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\n",
    "tokenizer.fit_on_texts(texts_train)\n",
    "sequences = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_index = tokenizer.word_index\n",
    "#print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMAX_SEQUENCE_LENGTH = 200\\n#pad sequences are used to bring all sentences to same size.\\n# pad sequences with 0s\\nx_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\\nx_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\\nprint('Shape of data tensor:', x_train.shape)\\nprint('Shape of data test tensor:', x_test.shape)\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "#pad sequences are used to bring all sentences to same size.\n",
    "# pad sequences with 0s\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of data test tensor:', x_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = df['airline_sentiment'].map({\"negative\": 0, \"neutral\" : 1,\"positive\":2 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nmodel.add(Embedding(MAX_NB_WORDS, 128))\\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,input_shape=(1,)))\\nmodel.add(Dense(3, activation='softmax'))\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,input_shape=(1,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, epochs = 7, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\\nfull_tfidf = tfidf_vec.fit_transform(df['text'].values.tolist() + df2['text'].values.tolist())\\ntrain_tfidf = tfidf_vec.transform(df['text'].values.tolist())\\ntest_tfidf = tfidf_vec.transform(df2['text'].values.tolist())\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "full_tfidf = tfidf_vec.fit_transform(df['text'].values.tolist() + df2['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(df['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(df2['text'].values.tolist())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg.fit(train_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions1=logreg.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['pred']=predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train=df['text'].astype(str)\n",
    "texts_test=df2['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_text = pd.concat([texts_train, texts_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=5000)\n",
    "full_tfidf_word=word_vectorizer.fit_transform(df['text'].values.tolist() + df2['text'].values.tolist())\n",
    "train_tfidf_word = word_vectorizer.transform(df['text'].values.tolist())\n",
    "test_tfidf_word = word_vectorizer.transform(df2['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()\n",
    "df2=df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_comp = 20\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf_word)\n",
    "train_svd_word = pd.DataFrame(svd_obj.transform(train_tfidf_word))\n",
    "test_svd_word = pd.DataFrame(svd_obj.transform(test_tfidf_word))\n",
    "    \n",
    "train_svd_word.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd_word.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "df = pd.concat([df, train_svd_word], axis=1)\n",
    "df2 = pd.concat([df2, test_svd_word], axis=1)\n",
    "del full_tfidf_word, train_tfidf_word, test_tfidf_word, train_svd_word, test_svd_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>1.562552e-15</td>\n",
       "      <td>-7.255481e-15</td>\n",
       "      <td>2.872268e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>9.083446e-16</td>\n",
       "      <td>3.079459e-15</td>\n",
       "      <td>8.528768e-15</td>\n",
       "      <td>-5.747356e-16</td>\n",
       "      <td>-1.513481e-14</td>\n",
       "      <td>8.277667e-15</td>\n",
       "      <td>6.662206e-15</td>\n",
       "      <td>-1.639314e-16</td>\n",
       "      <td>7.414208e-15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "0      3  Tr_tweet_4                           1.0                     0.7033   \n",
       "\n",
       "          airline  retweet_count  \\\n",
       "0  Virgin America            0.0   \n",
       "\n",
       "                                                text    svd_word_0  \\\n",
       "0  0       VirginAmerica Really missed a prime op...  1.562552e-15   \n",
       "\n",
       "     svd_word_1    svd_word_2     ...        svd_word_10   svd_word_11  \\\n",
       "0 -7.255481e-15  2.872268e-15     ...       9.083446e-16  3.079459e-15   \n",
       "\n",
       "    svd_word_12   svd_word_13   svd_word_14   svd_word_15   svd_word_16  \\\n",
       "0  8.528768e-15 -5.747356e-16 -1.513481e-14  8.277667e-15  6.662206e-15   \n",
       "\n",
       "    svd_word_17   svd_word_18  svd_word_19  \n",
       "0 -1.639314e-16  7.414208e-15          1.0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>svd_word_0</th>\n",
       "      <th>svd_word_1</th>\n",
       "      <th>svd_word_2</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_word_10</th>\n",
       "      <th>svd_word_11</th>\n",
       "      <th>svd_word_12</th>\n",
       "      <th>svd_word_13</th>\n",
       "      <th>svd_word_14</th>\n",
       "      <th>svd_word_15</th>\n",
       "      <th>svd_word_16</th>\n",
       "      <th>svd_word_17</th>\n",
       "      <th>svd_word_18</th>\n",
       "      <th>svd_word_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Test_tweet_1</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.651909</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>0       VirginAmerica Really missed a prime op...</td>\n",
       "      <td>1.562552e-15</td>\n",
       "      <td>-7.255481e-15</td>\n",
       "      <td>2.872268e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>9.083446e-16</td>\n",
       "      <td>3.079459e-15</td>\n",
       "      <td>8.528768e-15</td>\n",
       "      <td>-5.747356e-16</td>\n",
       "      <td>-1.513481e-14</td>\n",
       "      <td>8.277667e-15</td>\n",
       "      <td>6.662206e-15</td>\n",
       "      <td>-1.639314e-16</td>\n",
       "      <td>7.414208e-15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      tweet_id  airline_sentiment_confidence  \\\n",
       "0      0  Test_tweet_1                         0.634   \n",
       "\n",
       "   negativereason_confidence         airline  retweet_count  \\\n",
       "0                   0.651909  Virgin America              0   \n",
       "\n",
       "                                                text    svd_word_0  \\\n",
       "0  0       VirginAmerica Really missed a prime op...  1.562552e-15   \n",
       "\n",
       "     svd_word_1    svd_word_2     ...        svd_word_10   svd_word_11  \\\n",
       "0 -7.255481e-15  2.872268e-15     ...       9.083446e-16  3.079459e-15   \n",
       "\n",
       "    svd_word_12   svd_word_13   svd_word_14   svd_word_15   svd_word_16  \\\n",
       "0  8.528768e-15 -5.747356e-16 -1.513481e-14  8.277667e-15  6.662206e-15   \n",
       "\n",
       "    svd_word_17   svd_word_18  svd_word_19  \n",
       "0 -1.639314e-16  7.414208e-15          1.0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.drop(['index','text','tweet_id'],axis=1)\n",
    "test=df2.drop(['index','text','tweet_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_map = {'Virgin America':1, 'United':2}\n",
    "\n",
    "train['airline'] = train['airline'].map(airline_map)\n",
    "test['airline'] = test['airline'].map(airline_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.naive_bayes import GaussianNB\\n\\ngb=GaussianNB()\\ngb.fit(train,y)\\n\\npred=gb.predict(test)\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gb=GaussianNB()\n",
    "gb.fit(train,y)\n",
    "\n",
    "pred=gb.predict(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import LogisticRegression\\n\\nlg=LogisticRegression()\\nlg.fit(train,y)\\npred=lg.predict(test)\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg=LogisticRegression()\n",
    "lg.fit(train,y)\n",
    "pred=lg.predict(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn import preprocessing\\n\\ntrain=preprocessing.StandardScaler().fit_transform(train)\\ntest=preprocessing.StandardScaler().fit_transform(test)\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train=preprocessing.StandardScaler().fit_transform(train)\n",
    "test=preprocessing.StandardScaler().fit_transform(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nrf=RandomForestClassifier()\\nrf.fit(train,y)\\npred=rf.predict(test)\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(train,y)\n",
    "pred=rf.predict(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debadri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb=lgb.LGBMClassifier()\n",
    "\n",
    "lgb.fit(train,y)\n",
    "pred=lgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = LogisticRegression(C=0.1, solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.fit(train_features, df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred=classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsubmissions=pd.DataFrame(columns=['tweet_id', 'airline_sentiment'])\\nsubmissions['tweet_id']=df2['tweet_id']\\nsubmissions['airline_sentiment']=pred\\nsubmissions.to_csv('tweet.csv', index=False)\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "submissions=pd.DataFrame(columns=['tweet_id', 'airline_sentiment'])\n",
    "submissions['tweet_id']=df2['tweet_id']\n",
    "submissions['airline_sentiment']=pred\n",
    "submissions.to_csv('tweet.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pred']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    336\n",
       "neutral      30\n",
       "positive      5\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    43\n",
       "neutral     30\n",
       "positive     5\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.ix[df2['negativereason_confidence']<0.5]['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame(columns=['tweet_id', 'airline_sentiment'])\n",
    "submissions['tweet_id']=df2['tweet_id']\n",
    "submissions['airline_sentiment']=pred\n",
    "submissions.to_csv('tweet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
